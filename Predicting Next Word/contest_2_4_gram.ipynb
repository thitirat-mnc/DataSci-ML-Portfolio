{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow"
      ],
      "metadata": {
        "id": "x3ADnHLsYxWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "unAhF47mTXiZ",
        "outputId": "67a4b512-6863-41cb-99eb-46d31193a557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n078of1Wy2l",
        "outputId": "c07f94ec-6406-4fb4-d571-65b38991d7bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtcxawmWWVAO",
        "outputId": "50577c33-6e2f-4f30-e206-7dc7fccbdf6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7409 sha256=3c39a66f29415b7ca3c129adb1d011df3fc3957cda069ccc9e0ab64fd375a147\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/b5/24/fbb56595c286984f7315ee31821d6121e1b9828436021a88b3\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (5.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.9/dist-packages (0.5.1)\n",
            "Gen RAM Free: 11.5 GB  | Proc size: 1.3 GB\n",
            "GPU RAM Free: 14768MB | Used: 333MB | Util   2% | Total 15360MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train n-gram"
      ],
      "metadata": {
        "id": "7lSkc3v8Y2kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcKth7u-Q0ZM",
        "outputId": "f40f4200-b360-4c0c-c839-32abdcfc3202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDty6BIaP3OF"
      },
      "outputs": [],
      "source": [
        "batch_size = 2048\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def train_fourgram(tokens, fourgram_counts):\n",
        "    batches = [tokens[i:i+batch_size] for i in range(0, len(tokens), batch_size)]\n",
        "    for batch in batches:\n",
        "        for i in range(len(batch)-3):\n",
        "            context = tuple(batch[i:i+3])\n",
        "            word = batch[i+3]\n",
        "            fourgram_counts[context][word] += 1\n",
        "    return fourgram_counts\n",
        "\n",
        "def create_fourgram_model(fourgram_counts):\n",
        "    model = defaultdict(Counter)\n",
        "    for context, counts in fourgram_counts.items():\n",
        "        total_count = sum(counts.values())\n",
        "        for word, count in counts.items():\n",
        "            prob = count / total_count\n",
        "            model[context][word] = prob\n",
        "    return model\n",
        "\n",
        "with open('/content/drive/MyDrive/com ling/contest 2/contest 2/train.src.tok', 'r') as f:\n",
        "    counts_dict = defaultdict(Counter)\n",
        "    chunk_size = 50000\n",
        "    tokens = []\n",
        "    for i, line in enumerate(f):\n",
        "        line_tokens = line.strip().split() # tokenize the line\n",
        "        tokens.extend(line_tokens) # add tokens to list\n",
        "        if len(tokens) > chunk_size:\n",
        "            # process the chunk of tokens\n",
        "            counts_dict = train_fourgram(tokens, counts_dict)\n",
        "            # reset the tokens list for the next chunk\n",
        "            tokens = []\n",
        "    # process the remaining tokens\n",
        "    if len(tokens) > 0:\n",
        "        counts_dict = train_fourgram(tokens, counts_dict)\n",
        "\n",
        "# create the 4-gram model from the counts dictionary\n",
        "model = create_fourgram_model(counts_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(counts_dict)"
      ],
      "metadata": {
        "id": "rx8OObJ-Q5DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_word(fourgram_context1, fourgram_context2, fourgram_context3, counter, first_letter):\n",
        "    if (fourgram_context1, fourgram_context2, fourgram_context3) in counter:\n",
        "        # get all the words in the given context that start with the given first letter\n",
        "        words = [word for word in counter[fourgram_context1, fourgram_context2, fourgram_context3] if word[0] == first_letter]\n",
        "        if len(words) > 0:\n",
        "            # sort the words by their frequency and return the most common word\n",
        "            return max(words, key=counter[fourgram_context1, fourgram_context2, fourgram_context3].get)\n",
        "        else:\n",
        "            # if no words match the given first letter, return an empty string\n",
        "            return ''\n",
        "    else:\n",
        "        # return an empty string to represent an unknown context\n",
        "        return ''"
      ],
      "metadata": {
        "id": "jxWogtozQuPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_word = predict_word('the', 'next','month' model, 'i')\n",
        "print(next_word)"
      ],
      "metadata": {
        "id": "EgPUSpwnRMBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "6u4yuB-8RQs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dev = pd.read_csv('/content/drive/MyDrive/com ling/contest 2/contest 2/dev_set.csv')"
      ],
      "metadata": {
        "id": "4a4N1vbKRRMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev['tokens'] = dev.context.apply(lambda x: x.split())\n",
        "dev"
      ],
      "metadata": {
        "id": "rgP8nWPNRbyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_set = dev[['tokens', 'first letter']]\n",
        "dev_set"
      ],
      "metadata": {
        "id": "339uyklxRdug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = []\n",
        "for i, row in dev_set.iterrows():\n",
        "  tokens = row['tokens']\n",
        "  possible_first_letter = row['first letter']\n",
        "  next_word = predict_word(tokens[-3],tokens[-2], tokens[-1], model, possible_first_letter)\n",
        "  prediction.append(next_word)\n",
        "print(prediction[:100])"
      ],
      "metadata": {
        "id": "K-fBmAKQRd2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_set['prediction'] = prediction"
      ],
      "metadata": {
        "id": "l663jKMaRd9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(actual, predicted):\n",
        "    correct = 0\n",
        "    for i in range(len(actual)):\n",
        "        if actual[i] == predicted[i]:\n",
        "            correct += 1\n",
        "\n",
        "    acc = correct / len(actual)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "RSylvVgvRj3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual = dev['answer']\n",
        "predicted = dev_set['prediction']"
      ],
      "metadata": {
        "id": "C6XMd7KORlyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(actual, predicted)"
      ],
      "metadata": {
        "id": "CHp3L10JRnmR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}